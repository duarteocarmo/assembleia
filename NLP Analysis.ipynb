{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise preliminar de linguagem nos discursos do Parlamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Importar dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começamos por importar algumas libraries necessárias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "from spacy.lang.pt import Portuguese\n",
    "from nltk.stem import RSLPStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E extraimos um numero limitado de discursos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_FILES_TO_LOAD = 15\n",
    "FILES_DIRECTORY = \"data/debates/\"\n",
    "\n",
    "parties = []\n",
    "speakers = []\n",
    "contents = []\n",
    "\n",
    "for file_name in os.listdir(FILES_DIRECTORY)[:JSON_FILES_TO_LOAD]:\n",
    "    with open(FILES_DIRECTORY + file_name) as file:\n",
    "        json_data = json.load(file)\n",
    "        for number, intervention in json_data['intervenções'].items():\n",
    "            speakers.append(intervention[\"orador\"])\n",
    "            parties.append(intervention[\"partido\"])\n",
    "            contents.append(intervention[\"discurso\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualizar um exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orador:  Cristóvão Simão Ribeiro\n",
      "Partido:  PSD\n",
      "Discurso:  Sr. Presidente, Srs. Membros do Governo, Sr.as Deputadas e Srs. Deputados: Dirijo um cumprimento especial aos estudantes de medicina que se encontram a assistir à sessão. Vou citar um ex-Primeiro-Ministro e começar por dizer o seguinte: quando queremos ser coerentes não podemos ser originais todos os dias. Este é um assunto de tal maneira debatido e replicado nesta Câmara que vou dizer exatamente aquilo que disse nas últimas três ou quatro vezes que este assunto foi aqui trazido repetidamente desde que os senhores são Governo e que a esquerda parlamentar os apoia. Vou dizê-lo em quatro notas particulares. Primeira nota: é evidentemente lesivo e um autêntico defraudar de expetativas, quer para os estudantes, quer para as suas famílias e, ainda pior, altamente lesivo para o Serviço Nacional de Saúde aquilo que é o desperdício de rios de dinheiro em formação médica sem depois haver uma consequência na formação médica especializada que, justamente, esses estudantes e esses jovens ambicionam e que legitimamente os utentes do SNS precisam.\n"
     ]
    }
   ],
   "source": [
    "indice = 899\n",
    "print(\"Orador: \", speakers[indice])\n",
    "print(\"Partido: \", parties[indice])\n",
    "print(\"Discurso: \", contents[indice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantos recolhemos no total? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oradores: 262\n",
      "Partidos: 8\n",
      "Discursos: 3756\n"
     ]
    }
   ],
   "source": [
    "print(f\"Oradores: {len(list(set(speakers)))}\")\n",
    "print(f\"Partidos: {len(list(set(parties)))}\")\n",
    "print(f\"Discursos: {len(contents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Limpeza de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **De palavras para tokens limpos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos a função `tokenize`,  uma função que limpa o texto de acordo com um numero de regras (é texto? é um numero? é pontuação?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloadamos os recursos necessários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.load('pt')\n",
    "parser = Portuguese()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E criamos a função "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokenized_text = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.is_digit:\n",
    "            continue\n",
    "        if token.is_space:\n",
    "            continue\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        #if token.is_title:\n",
    "        #    continue\n",
    "        if token.is_alpha:\n",
    "            tokenized_text.append(token.lower_)\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **limpar a lista com stopwords**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos a lista de `stopwords` que se encontrão no ficheiro `data/nlp/stopwords.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/nlp/stopwords.txt\") as file: \n",
    "    custom_stopwords = file.readlines()\n",
    "custom_stopwords = [line.strip() for line in custom_stopwords] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **stemmer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um primeiro stemmer baseado [neste](https://www.nltk.org/_modules/nltk/stem/rslp.html) algoritmo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loadamos os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/duarteocarmo/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('rslp')\n",
    "st = RSLPStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E criamos a função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_rslp(tokens):\n",
    "    stemmed = []\n",
    "    for token in tokens:\n",
    "        stemmed.append(st.stem(word))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **lemmatizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um stemmer alternativo baseado num modelo de noticias da library `spacy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loadamos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_pt = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E criamos a função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_spacy(tokens):\n",
    "    text = \" \".join(tokens)\n",
    "    lemma = []\n",
    "    for token in spacy_pt(text):\n",
    "        if token.lemma_:\n",
    "            lemma.append(token.lemma_)\n",
    "        else:\n",
    "            lemma.append(token)\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Função de limpeza de texto**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos finalmente prontos para criar uma função que recebe um discurso e limpa o totalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = lemmatize_spacy(tokens)\n",
    "    #tokens = stem_rslp(tokens)\n",
    "    tokens = [token for token in tokens if token not in custom_stopwords]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar com o mesmo exemplo de acima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto Original:\n",
      "Sr. Presidente, Srs. Membros do Governo, Sr.as Deputadas e Srs. Deputados: Dirijo um cumprimento especial aos estudantes de medicina que se encontram a assistir à sessão. Vou citar um ex-Primeiro-Ministro e começar por dizer o seguinte: quando queremos ser coerentes não podemos ser originais todos os dias. Este é um assunto de tal maneira debatido e replicado nesta Câmara que vou dizer exatamente aquilo que disse nas últimas três ou quatro vezes que este assunto foi aqui trazido repetidamente desde que os senhores são Governo e que a esquerda parlamentar os apoia. Vou dizê-lo em quatro notas particulares. Primeira nota: é evidentemente lesivo e um autêntico defraudar de expetativas, quer para os estudantes, quer para as suas famílias e, ainda pior, altamente lesivo para o Serviço Nacional de Saúde aquilo que é o desperdício de rios de dinheiro em formação médica sem depois haver uma consequência na formação médica especializada que, justamente, esses estudantes e esses jovens ambicionam e que legitimamente os utentes do SNS precisam.\n",
      "- - - - - - - - - - \n",
      "Texto Limpo:\n",
      "['presidente', 'sr', 'membro', 'governar', 'deputar', 'sr', 'deputar', 'dirigir', 'cumprimentar', 'especial', 'estudante', 'medicinar', 'encontrar', 'assistir', 'sessão', 'citar', 'começar', 'seguinte', 'querer', 'coerente', 'originar', 'assunto', 'maneiro', 'debater', 'replicar', 'n', 'câmara', 'exatamente', 'assunto', 'trazer', 'repetidamente', 'senhor', 'governar', 'esquerdo', 'parlamentar', 'noto', 'particular', 'noto', 'evidentemente', 'lesivo', 'autêntico', 'defraudar', 'expetativas', 'estudante', 'família', 'altamente', 'lesivo', 'serviço', 'nacional', 'saudar', 'desperdício', 'rio', 'dinheiro', 'formação', 'médico', 'haver', 'consequência', 'formação', 'médico', 'especializar', 'justamente', 'estudante', 'jovem', 'ambicionar', 'legitimamente', 'utente', 'sns', 'precisar']\n"
     ]
    }
   ],
   "source": [
    "texto_original = contents[indice]\n",
    "tokens_limpos = prepare_text(texto_original)\n",
    "texto_limpo = \" \".join(tokens_limpos)\n",
    "\n",
    "print(f\"Texto Original:\\n{texto_original}\")\n",
    "print(\"- \" * 10)\n",
    "print(f\"Texto Limpo:\\n{tokens_limpos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece produzir um resultado *aceitavel*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (assembleia)",
   "language": "python",
   "name": "assembleia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
